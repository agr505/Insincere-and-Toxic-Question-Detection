{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM with Attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLYf5CaOdiQB",
        "colab_type": "text"
      },
      "source": [
        "# Mount Drive and Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkeZSEZRdF4r",
        "colab_type": "code",
        "outputId": "712a1fbc-d197-42db-c373-d6aa71f896fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEbEQAmcdaY6",
        "colab_type": "code",
        "outputId": "3f48174d-f2ea-435b-adea-7c7c866535bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/CSE/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "biLstm_model.pkl     train.csv\t      val_split.csv\n",
            "glove.840B.300d.txt  train_split.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE5kqGo4dS_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/CSE/train_split.csv /content/train_split.csv\n",
        "!cp /content/drive/My\\ Drive/CSE/val_split.csv /content/val_split.csv\n",
        "!cp /content/drive/My\\ Drive/CSE/glove.840B.300d.txt /content/glove.840B.300d.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXrsETXdruL",
        "colab_type": "code",
        "outputId": "8c3389f2-a978-4307-d3a2-e920e459e198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "!pip install pandas==1.0.0\n",
        "\n",
        "import numpy as pd\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/d1/a6502c2f5c15b50f5dd579fc1c52b47edf6f2e9f682aed917dd7565b3e60/pandas-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (1.17.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.0) (1.12.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 1.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "Successfully installed pandas-1.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajTzyqnhdsT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the raw dataset\n",
        "df = pd.read_csv('train_split.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHDKCobjdhFB",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hZaNzeud2Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import nltk\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def save_model(model, model_path):\n",
        "    \"\"\"Save model.\"\"\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "\n",
        "def load_model(model, model_path, use_cuda=False):\n",
        "    \"\"\"Load model.\"\"\"\n",
        "    map_location = 'cpu'\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        map_location = 'cuda:0'\n",
        "    model.load_state_dict(torch.load(model_path, map_location))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPixz-XcedVY",
        "colab_type": "code",
        "outputId": "9171b129-1b56-4364-f1b2-6daeb4ac9c4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "use_gpu = True\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV5B0DNAesZA",
        "colab_type": "text"
      },
      "source": [
        "## Model, Trainer, Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB887XG2euME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NEG_INF = -10000\n",
        "TINY_FLOAT = 1e-6\n",
        "\n",
        "def mask_softmax(matrix, mask=None):\n",
        "    \"\"\"Perform softmax on length dimension with masking.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    matrix: torch.float, shape [batch_size, .., max_len]\n",
        "    mask: torch.long, shape [batch_size, max_len]\n",
        "        Mask tensor for sequence.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    output: torch.float, shape [batch_size, .., max_len]\n",
        "        Normalized output in length dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    if mask is None:\n",
        "        result = F.softmax(matrix, dim=-1)\n",
        "    else:\n",
        "        mask_norm = ((1 - mask) * NEG_INF).to(matrix)\n",
        "        for i in range(matrix.dim() - mask_norm.dim()):\n",
        "            mask_norm = mask_norm.unsqueeze(1)\n",
        "        result = F.softmax(matrix + mask_norm, dim=-1)\n",
        "\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-As2504hR-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_mean(seq, mask=None):\n",
        "    \"\"\"Compute mask average on length dimension.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    seq : torch.float, size [batch, max_seq_len, n_channels],\n",
        "        Sequence vector.\n",
        "    mask : torch.long, size [batch, max_seq_len],\n",
        "        Mask vector, with 0 for mask.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mask_mean : torch.float, size [batch, n_channels]\n",
        "        Mask mean of sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    if mask is None:\n",
        "        return torch.mean(seq, dim=1)\n",
        "\n",
        "    mask_sum = torch.sum(  # [b,msl,nc]->[b,nc]\n",
        "        seq * mask.unsqueeze(-1).float(), dim=1)\n",
        "    seq_len = torch.sum(mask, dim=-1)  # [b]\n",
        "    mask_mean = mask_sum / (seq_len.unsqueeze(-1).float() + TINY_FLOAT)\n",
        "\n",
        "    return mask_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l3xQ2y3hYSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_max(seq, mask=None):\n",
        "    \"\"\"Compute mask max on length dimension.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    seq : torch.float, size [batch, max_seq_len, n_channels],\n",
        "        Sequence vector.\n",
        "    mask : torch.long, size [batch, max_seq_len],\n",
        "        Mask vector, with 0 for mask.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mask_max : torch.float, size [batch, n_channels]\n",
        "        Mask max of sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    if mask is None:\n",
        "        return torch.mean(seq, dim=1)\n",
        "\n",
        "    torch\n",
        "    mask_max, _ = torch.max(  # [b,msl,nc]->[b,nc]\n",
        "        seq + (1 - mask.unsqueeze(-1).float()) * NEG_INF,\n",
        "        dim=1)\n",
        "\n",
        "    return mask_max\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3DLuO4RhYYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_mask(seq_len, max_len):\n",
        "    \"\"\"Create sequence mask.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    seq_len: torch.long, shape [batch_size],\n",
        "        Lengths of sequences in a batch.\n",
        "    max_len: int\n",
        "        The maximum sequence length in a batch.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mask: torch.long, shape [batch_size, max_len]\n",
        "        Mask tensor for sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    idx = torch.arange(max_len).to(seq_len).repeat(seq_len.size(0), 1)\n",
        "    mask = torch.gt(seq_len.unsqueeze(1), idx).to(seq_len)\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b311LK-zhYax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynamicLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Dynamic LSTM module, which can handle variable length input sequence.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_size : input size\n",
        "    hidden_size : hidden size\n",
        "    num_layers : number of hidden layers. Default: 1\n",
        "    dropout : dropout rate. Default: 0.5\n",
        "    bidirectional : If True, becomes a bidirectional RNN. Default: False.\n",
        "\n",
        "    Inputs\n",
        "    ------\n",
        "    input: tensor, shaped [batch, max_step, input_size]\n",
        "    seq_lens: tensor, shaped [batch], sequence lengths of batch\n",
        "\n",
        "    Outputs\n",
        "    -------\n",
        "    output: tensor, shaped [batch, max_step, num_directions * hidden_size],\n",
        "         tensor containing the output features (h_t) from the last layer\n",
        "         of the LSTM, for each t.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size=100,\n",
        "                 num_layers=1, dropout=0., bidirectional=False):\n",
        "        super(DynamicLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size, hidden_size, num_layers, bias=True,\n",
        "            batch_first=True, dropout=dropout, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, x, seq_lens):\n",
        "        # sort input by descending length\n",
        "        _, idx_sort = torch.sort(seq_lens, dim=0, descending=True)\n",
        "        _, idx_unsort = torch.sort(idx_sort, dim=0)\n",
        "        x_sort = torch.index_select(x, dim=0, index=idx_sort)\n",
        "        seq_lens_sort = torch.index_select(seq_lens, dim=0, index=idx_sort)\n",
        "\n",
        "        # pack input\n",
        "        x_packed = pack_padded_sequence(\n",
        "            x_sort, seq_lens_sort, batch_first=True)\n",
        "\n",
        "        # pass through rnn\n",
        "        y_packed, _ = self.lstm(x_packed)\n",
        "\n",
        "        # unpack output\n",
        "        y_sort, length = pad_packed_sequence(y_packed, batch_first=True)\n",
        "\n",
        "        # unsort output to original order\n",
        "        y = torch.index_select(y_sort, dim=0, index=idx_unsort)\n",
        "\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLBJ9GPyhYdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    \"\"\"Model for quora insincere question classification.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, args):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        vocab_size = args[\"vocab_size\"]\n",
        "        pretrained_embed = args[\"pretrained_embed\"]\n",
        "        padding_idx = args[\"padding_idx\"]\n",
        "        embed_dim = 300\n",
        "        num_classes = 1\n",
        "        num_layers = 2\n",
        "        hidden_dim = 50\n",
        "        dropout = 0.5\n",
        "\n",
        "        if pretrained_embed is None:\n",
        "            self.embed = nn.Embedding(vocab_size, embed_dim)\n",
        "        else:\n",
        "            self.embed = nn.Embedding.from_pretrained(\n",
        "                pretrained_embed, freeze=False)\n",
        "        self.embed.padding_idx = padding_idx\n",
        "\n",
        "        self.rnn = DynamicLSTM(\n",
        "            embed_dim, hidden_dim, num_layers=num_layers,\n",
        "            dropout=dropout, bidirectional=True)\n",
        "\n",
        "        self.fc_att = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 6, hidden_dim)\n",
        "        self.act = nn.ReLU()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, word_seq, seq_len):\n",
        "        # mask\n",
        "        max_seq_len = torch.max(seq_len)\n",
        "        mask = seq_mask(seq_len, max_seq_len)  # [b,msl]\n",
        "\n",
        "        # embed\n",
        "        e = self.drop(self.embed(word_seq))  # [b,msl]->[b,msl,e]\n",
        "\n",
        "        # bi-rnn\n",
        "        r = self.rnn(e, seq_len)  # [b,msl,e]->[b,msl,h*2]\n",
        "\n",
        "        # attention\n",
        "        att = self.fc_att(r).squeeze(-1)  # [b,msl,h*2]->[b,msl]\n",
        "        att = mask_softmax(att, mask)  # [b,msl]\n",
        "        r_att = torch.sum(att.unsqueeze(-1) * r, dim=1)  # [b,h*2]\n",
        "\n",
        "        # pooling\n",
        "        r_avg = mask_mean(r, mask)  # [b,h*2]\n",
        "        r_max = mask_max(r, mask)  # [b,h*2]\n",
        "        r = torch.cat([r_avg, r_max, r_att], dim=-1)  # [b,h*6]\n",
        "\n",
        "        # feed-forward\n",
        "        f = self.drop(self.act(self.fc(r)))  # [b,h*6]->[b,h]\n",
        "        logits = self.out(f).squeeze(-1)  # [b,h]->[b]\n",
        "\n",
        "        return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x0k0GIPhYjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer(object):\n",
        "    \"\"\"Trainer.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.n_epochs = kwargs[\"epochs\"]\n",
        "        self.batch_size = kwargs[\"batch_size\"]\n",
        "        self.validate = kwargs[\"validate\"]\n",
        "        self.save_best_dev = kwargs[\"save_best_dev\"]\n",
        "        self.use_cuda = kwargs[\"use_cuda\"]\n",
        "        self.print_every_step = kwargs[\"print_every_step\"]\n",
        "        self.optimizer = kwargs[\"optimizer\"]\n",
        "        self.model_path = kwargs[\"model_path\"]\n",
        "        self.eval_metrics = kwargs[\"eval_metrics\"]\n",
        "\n",
        "        self._best_accuracy = 0.0\n",
        "\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available() and self.use_cuda:\n",
        "            self.device = 'cuda:0'\n",
        "\n",
        "    def train(self, network, train_data, dev_data=None):\n",
        "        # transfer model to gpu if available\n",
        "        network = network.to(self.device)\n",
        "\n",
        "        # define batch iterator\n",
        "        train_iter = torchtext.data.Iterator(\n",
        "            dataset=train_data, batch_size=self.batch_size,\n",
        "            train=True, shuffle=True, sort=False,\n",
        "            device=self.device)\n",
        "\n",
        "        # define Tester over dev data\n",
        "        if self.validate:\n",
        "            default_valid_args = {\n",
        "                \"batch_size\": max(8, self.batch_size // 10),\n",
        "                \"use_cuda\": self.use_cuda}\n",
        "            validator = Tester(**default_valid_args)\n",
        "\n",
        "        start = time.time()\n",
        "        for epoch in range(1, self.n_epochs + 1):\n",
        "            # turn on network training mode\n",
        "            network.train()\n",
        "\n",
        "            # initialize iterator\n",
        "            train_iter.init_epoch()\n",
        "\n",
        "            # one forward and backward pass\n",
        "            self._train_step(\n",
        "                train_iter, network, start=start,\n",
        "                n_print=self.print_every_step, epoch=epoch)\n",
        "\n",
        "            # validation\n",
        "            if self.validate:\n",
        "                if dev_data is None:\n",
        "                    raise RuntimeError(\n",
        "                        \"self.validate is True in trainer, \"\n",
        "                        \"but dev_data is None.\"\n",
        "                        \" Please provide the validation data.\")\n",
        "                eval_results = validator.test(network, dev_data)\n",
        "\n",
        "                if self.save_best_dev and self.best_eval_result(eval_results):\n",
        "                    save_model(network, self.model_path)\n",
        "                    print(\"Saved better model selected by validation.\")\n",
        "\n",
        "    def _train_step(self, data_iterator, network, **kwargs):\n",
        "        \"\"\"Training process in one epoch.\n",
        "        \"\"\"\n",
        "        step = 0\n",
        "        for batch in data_iterator:\n",
        "            (text, text_len), target = batch.text, batch.target\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            logits = network(text, text_len)\n",
        "            loss = network.loss(logits, target.float())\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if kwargs[\"n_print\"] > 0 and step % kwargs[\"n_print\"] == 0:\n",
        "                end = time.time()\n",
        "                diff = timedelta(seconds=round(end - kwargs[\"start\"]))\n",
        "                print_output = \"[epoch: {:>3} step: {:>4}]\" \\\n",
        "                    \" train loss: {:>4.6} time: {}\".format(\n",
        "                        kwargs[\"epoch\"], step, loss.item(), diff)\n",
        "                print(print_output)\n",
        "\n",
        "            step += 1\n",
        "\n",
        "    def best_eval_result(self, eval_results):\n",
        "        \"\"\"Check if the current epoch yields better validation results.\n",
        "\n",
        "        :param eval_results: dict, format {metrics_name: value}\n",
        "        :return: bool, True means current results on dev set is the best.\n",
        "        \"\"\"\n",
        "        assert self.eval_metrics in eval_results, \\\n",
        "            \"Evaluation doesn't contain metrics '{}'.\" \\\n",
        "            .format(self.eval_metrics)\n",
        "\n",
        "        accuracy = eval_results[self.eval_metrics]\n",
        "        if accuracy > self._best_accuracy:\n",
        "            self._best_accuracy = accuracy\n",
        "            return True\n",
        "        else:\n",
        "            return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkItN3jahYln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tester(object):\n",
        "    \"\"\"Tester.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.batch_size = kwargs[\"batch_size\"]\n",
        "        self.use_cuda = kwargs[\"use_cuda\"]\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available() and self.use_cuda:\n",
        "            self.device = 'cuda:0'\n",
        "\n",
        "    def test(self, network, dev_data, threshold=0.33):\n",
        "        # transfer model to gpu if available\n",
        "        network = network.to(self.device)\n",
        "\n",
        "        # turn on the testing mode; clean up the history\n",
        "        network.eval()\n",
        "        output_list = []\n",
        "        truth_list = []\n",
        "\n",
        "        # define batch iterator\n",
        "        data_iter = torchtext.data.Iterator(\n",
        "            dataset=dev_data, batch_size=self.batch_size,\n",
        "            train=False, device=self.device, sort=False)\n",
        "\n",
        "        # predict\n",
        "        for batch in data_iter:\n",
        "            text, target = batch.text, batch.target\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = network(*text)\n",
        "\n",
        "            output_list.append(prediction.detach())\n",
        "            truth_list.append(target.detach())\n",
        "\n",
        "        # evaluate\n",
        "        eval_results = self.evaluate(output_list, truth_list, threshold)\n",
        "        print(\"[tester] {}\".format(self.print_eval_results(eval_results)))\n",
        "\n",
        "        return eval_results\n",
        "\n",
        "    def evaluate(self, predict, truth, threshold=0.33):\n",
        "        \"\"\"Compute evaluation metrics.\n",
        "\n",
        "        :param predict: list of Tensor\n",
        "        :param truth: list of dict\n",
        "        :param threshold: threshold of positive probability\n",
        "        :return eval_results: dict, format {name: metrics}.\n",
        "        \"\"\"\n",
        "        y_trues, y_preds = [], []\n",
        "        for y_true, logit in zip(truth, predict):\n",
        "            y_pred = (torch.sigmoid(logit) > threshold).long().cpu().numpy()\n",
        "            y_true = y_true.cpu().numpy()\n",
        "            y_trues.append(y_true)\n",
        "            y_preds.append(y_pred)\n",
        "        y_true = np.concatenate(y_trues, axis=0)\n",
        "        y_pred = np.concatenate(y_preds, axis=0)\n",
        "\n",
        "        precision = metrics.precision_score(y_true, y_pred, pos_label=1)\n",
        "        recall = metrics.recall_score(y_true, y_pred, pos_label=1)\n",
        "        f1 = metrics.f1_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "        metrics_dict = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "        return metrics_dict\n",
        "\n",
        "    def print_eval_results(self, results):\n",
        "        \"\"\"Override this method to support more print formats.\n",
        "        :param results: dict, (str: float) is (metrics name: value)\n",
        "        \"\"\"\n",
        "        return \", \".join(\n",
        "            [str(key) + \"=\" + \"{:.4f}\".format(value)\n",
        "             for key, value in results.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B74gTaGvhYn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Predictor(object):\n",
        "    \"\"\"An interface for predicting outputs based on trained models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size=8, use_cuda=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        self.device = 'cpu'\n",
        "        if torch.cuda.is_available() and self.use_cuda:\n",
        "            self.device = 'cuda:0'\n",
        "\n",
        "    def predict(self, network, data, threshold=0.33):\n",
        "        # transfer model to gpu if available\n",
        "        network = network.to(self.device)\n",
        "\n",
        "        # turn on the testing mode; clean up the history\n",
        "        network.eval()\n",
        "        output_list = []\n",
        "        truth_list = []\n",
        "\n",
        "        # define batch iterator\n",
        "        data_iter = torchtext.data.Iterator(\n",
        "            dataset=data, batch_size=self.batch_size,\n",
        "            train=False, device=self.device, sort=False)\n",
        "\n",
        "        for batch in data_iter:\n",
        "            text, target = batch.text, batch.target\n",
        "\n",
        "            with torch.no_grad():\n",
        "                prediction = network(*text)\n",
        "\n",
        "            output_list.append(prediction.detach())\n",
        "            truth_list.append(target.detach())\n",
        "\n",
        "        # evaluate\n",
        "        eval_results = self.evaluate(output_list, truth_list, threshold)\n",
        "        print(\"[tester] {}\".format(self.print_eval_results(eval_results)))\n",
        "\n",
        "        return eval_results\n",
        "\n",
        "    def evaluate(self, predict, truth, threshold=0.33):\n",
        "        \"\"\"Compute evaluation metrics.\n",
        "\n",
        "        :param predict: list of Tensor\n",
        "        :param truth: list of dict\n",
        "        :param threshold: threshold of positive probability\n",
        "        :return eval_results: dict, format {name: metrics}.\n",
        "        \"\"\"\n",
        "        y_trues, y_preds = [], []\n",
        "        for y_true, logit in zip(truth, predict):\n",
        "            y_pred = (torch.sigmoid(logit) > threshold).long().cpu().numpy()\n",
        "            y_true = y_true.cpu().numpy()\n",
        "            y_trues.append(y_true)\n",
        "            y_preds.append(y_pred)\n",
        "        y_true = np.concatenate(y_trues, axis=0)\n",
        "        y_pred = np.concatenate(y_preds, axis=0)\n",
        "\n",
        "        precision = metrics.precision_score(y_true, y_pred, pos_label=1)\n",
        "        recall = metrics.recall_score(y_true, y_pred, pos_label=1)\n",
        "        f1 = metrics.f1_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "        metrics_dict = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "        return metrics_dict\n",
        "\n",
        "    def print_eval_results(self, results):\n",
        "        \"\"\"Override this method to support more print formats.\n",
        "        :param results: dict, (str: float) is (metrics name: value)\n",
        "        \"\"\"\n",
        "        return \", \".join(\n",
        "            [str(key) + \"=\" + \"{:.4f}\".format(value)\n",
        "             for key, value in results.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTRJ2f-WggLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = './train_split.csv'\n",
        "test_path = './val_split.csv'\n",
        "embed_path = './glove.840B.300d.txt'\n",
        "model_path = '/content/drive/My Drive/CSE/biLstm_model.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Z1HixDhGWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre():\n",
        "    \"\"\"Pre-process model.\"\"\"\n",
        "\n",
        "    print(\"Pre-processing...\")\n",
        "\n",
        "    # load data\n",
        "    fix_length = 100\n",
        "    text = torchtext.data.Field(\n",
        "        sequential=True, use_vocab=True, lower=True,\n",
        "        tokenize=nltk.word_tokenize, batch_first=True,\n",
        "        is_target=False, fix_length=fix_length,\n",
        "        include_lengths=True)\n",
        "    target = torchtext.data.Field(\n",
        "        sequential=False, use_vocab=False,\n",
        "        batch_first=True, is_target=True)\n",
        "    dataset = torchtext.data.TabularDataset(\n",
        "        train_path, format='csv',\n",
        "        fields={\"cleaned_text\": ('text', text),\n",
        "                \"target\": ('target', target)})\n",
        "    data_test = torchtext.data.TabularDataset(\n",
        "        test_path, format='csv',\n",
        "        fields={\"cleaned_text\": ('text', text),\n",
        "                \"target\": ('target', target)})\n",
        "\n",
        "    # build vocab\n",
        "    text.build_vocab(dataset, data_test, min_freq=3)\n",
        "    text.vocab.load_vectors(torchtext.vocab.Vectors(embed_path))\n",
        "    vocab_size = len(text.vocab.itos)\n",
        "    padding_idx = text.vocab.stoi[text.pad_token]\n",
        "\n",
        "    # split data\n",
        "    data_train, data_val = dataset.split(split_ratio=0.9)\n",
        "\n",
        "    print(\"train set size:\", len(data_train))\n",
        "    print(\"val set size:\", len(data_val))\n",
        "    print(\"test set size:\", len(data_test))\n",
        "    print(\"vocab size:\", len(text.vocab.itos))\n",
        "    print(\"embed shape:\", text.vocab.vectors.shape)\n",
        "    print('')\n",
        "\n",
        "    args_dict = {\n",
        "        \"data_train\": data_train, \"data_val\": data_val,\n",
        "        \"data_test\": data_test, \"vocab_size\": vocab_size,\n",
        "        \"padding_idx\": padding_idx}\n",
        "\n",
        "    return args_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA7QB0_dildf",
        "colab_type": "code",
        "outputId": "43a8db14-cfee-4fb3-d090-cb28ad8d346f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "args = pre()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Pre-processing...\n",
            "train set size: 881632\n",
            "val set size: 97959\n",
            "test set size: 326531\n",
            "vocab size: 68947\n",
            "embed shape: torch.Size([68947, 300])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "citj6Tocin4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(**args):\n",
        "    \"\"\"Train model.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Training...\")\n",
        "\n",
        "    # load data and embed\n",
        "    data_train = args[\"data_train\"]\n",
        "    pretrained_embed = data_train.fields[\"text\"].vocab.vectors\n",
        "\n",
        "    # define model\n",
        "    model_args = {\n",
        "        \"vocab_size\": args[\"vocab_size\"],\n",
        "        \"padding_idx\": args[\"padding_idx\"],\n",
        "        \"pretrained_embed\": pretrained_embed,\n",
        "    }\n",
        "    model = Model(model_args)\n",
        "    load_model(model, model_path, use_cuda=True)\n",
        "\n",
        "    # define trainer\n",
        "    trainer_args = {\n",
        "        \"epochs\": 50,\n",
        "        \"batch_size\": 128,\n",
        "        \"validate\": True,\n",
        "        \"save_best_dev\": True,\n",
        "        \"use_cuda\": True,\n",
        "        \"print_every_step\": 1000,\n",
        "        \"optimizer\": torch.optim.Adam(model.parameters(), lr=1e-4),\n",
        "        \"model_path\": model_path,\n",
        "        \"eval_metrics\": \"f1\",\n",
        "    }\n",
        "    trainer = Trainer(**trainer_args)\n",
        "\n",
        "    # train\n",
        "    data_val = args[\"data_val\"]\n",
        "    trainer.train(model, data_train, dev_data=data_val)\n",
        "\n",
        "    print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUSgGFlljFjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(**args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtHNY_U9jF8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(**args):\n",
        "    \"\"\"Train model.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Testing...\")\n",
        "\n",
        "    # define model\n",
        "    model_args = {\n",
        "        \"vocab_size\": args[\"vocab_size\"],\n",
        "        \"padding_idx\": args[\"padding_idx\"],\n",
        "        \"pretrained_embed\": None,\n",
        "    }\n",
        "    model = Model(model_args)\n",
        "    load_model(model, model_path, use_cuda=True)\n",
        "\n",
        "    # define tester\n",
        "    tester_args = {\n",
        "        \"batch_size\": 128,\n",
        "        \"use_cuda\": True,\n",
        "    }\n",
        "    tester = Tester(**tester_args)\n",
        "\n",
        "    # test and threshold selection\n",
        "    data_val = args[\"data_val\"]\n",
        "    best_thresh, best_f1 = 0., 0.\n",
        "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "        thresh = np.round(thresh, 2)\n",
        "        f1 = tester.test(model, data_val, threshold=thresh)[\"f1\"]\n",
        "        print(\"threshold: {:>.2f} f1: {}\".format(thresh, f1))\n",
        "        if f1 > best_f1:\n",
        "            best_thresh, best_f1 = thresh, f1\n",
        "\n",
        "    args[\"threshold\"] = best_thresh\n",
        "\n",
        "    print(\"best f1 on dev: {} threshold: {:>.2f}\".format(best_f1, best_thresh))\n",
        "    print('')\n",
        "\n",
        "    return args"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGkrIt77jMxi",
        "colab_type": "code",
        "outputId": "4a1d1433-62d4-4cd6-9066-8c4908dfb4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " args = test(**args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n",
            "[tester] precision=0.4983, recall=0.8465, f1=0.6273\n",
            "threshold: 0.10 f1: 0.6273220049942141\n",
            "[tester] precision=0.5100, recall=0.8374, f1=0.6339\n",
            "threshold: 0.11 f1: 0.6339430135622746\n",
            "[tester] precision=0.5193, recall=0.8286, f1=0.6385\n",
            "threshold: 0.12 f1: 0.6384649483883225\n",
            "[tester] precision=0.5286, recall=0.8202, f1=0.6429\n",
            "threshold: 0.13 f1: 0.6428755475392941\n",
            "[tester] precision=0.5370, recall=0.8133, f1=0.6468\n",
            "threshold: 0.14 f1: 0.6468396627230538\n",
            "[tester] precision=0.5457, recall=0.8074, f1=0.6512\n",
            "threshold: 0.15 f1: 0.6511997878828053\n",
            "[tester] precision=0.5535, recall=0.8000, f1=0.6543\n",
            "threshold: 0.16 f1: 0.6542985817033004\n",
            "[tester] precision=0.5605, recall=0.7937, f1=0.6571\n",
            "threshold: 0.17 f1: 0.6570515001020478\n",
            "[tester] precision=0.5695, recall=0.7867, f1=0.6607\n",
            "threshold: 0.18 f1: 0.6606847045831034\n",
            "[tester] precision=0.5752, recall=0.7788, f1=0.6617\n",
            "threshold: 0.19 f1: 0.6616856364778996\n",
            "[tester] precision=0.5809, recall=0.7715, f1=0.6628\n",
            "threshold: 0.20 f1: 0.6628071166337193\n",
            "[tester] precision=0.5876, recall=0.7633, f1=0.6640\n",
            "threshold: 0.21 f1: 0.6640451848144706\n",
            "[tester] precision=0.5937, recall=0.7569, f1=0.6654\n",
            "threshold: 0.22 f1: 0.6654143486742288\n",
            "[tester] precision=0.6001, recall=0.7507, f1=0.6670\n",
            "threshold: 0.23 f1: 0.6670074485175991\n",
            "[tester] precision=0.6056, recall=0.7454, f1=0.6683\n",
            "threshold: 0.24 f1: 0.6682876510462717\n",
            "[tester] precision=0.6111, recall=0.7378, f1=0.6685\n",
            "threshold: 0.25 f1: 0.6685033507073715\n",
            "[tester] precision=0.6166, recall=0.7308, f1=0.6689\n",
            "threshold: 0.26 f1: 0.6688731758688129\n",
            "[tester] precision=0.6206, recall=0.7234, f1=0.6681\n",
            "threshold: 0.27 f1: 0.6680834914611006\n",
            "[tester] precision=0.6269, recall=0.7178, f1=0.6693\n",
            "threshold: 0.28 f1: 0.669272030651341\n",
            "[tester] precision=0.6318, recall=0.7110, f1=0.6691\n",
            "threshold: 0.29 f1: 0.6690897842394246\n",
            "[tester] precision=0.6364, recall=0.7033, f1=0.6682\n",
            "threshold: 0.30 f1: 0.6681761399125546\n",
            "[tester] precision=0.6406, recall=0.6964, f1=0.6673\n",
            "threshold: 0.31 f1: 0.6673491888486376\n",
            "[tester] precision=0.6449, recall=0.6903, f1=0.6668\n",
            "threshold: 0.32 f1: 0.6668254346272922\n",
            "[tester] precision=0.6492, recall=0.6834, f1=0.6659\n",
            "threshold: 0.33 f1: 0.665865962046601\n",
            "[tester] precision=0.6533, recall=0.6769, f1=0.6649\n",
            "threshold: 0.34 f1: 0.664890611124566\n",
            "[tester] precision=0.6582, recall=0.6691, f1=0.6636\n",
            "threshold: 0.35 f1: 0.6636237672181922\n",
            "[tester] precision=0.6629, recall=0.6616, f1=0.6622\n",
            "threshold: 0.36 f1: 0.6622244159262916\n",
            "[tester] precision=0.6672, recall=0.6553, f1=0.6612\n",
            "threshold: 0.37 f1: 0.6611940298507463\n",
            "[tester] precision=0.6727, recall=0.6507, f1=0.6615\n",
            "threshold: 0.38 f1: 0.6615423176539392\n",
            "[tester] precision=0.6767, recall=0.6440, f1=0.6599\n",
            "threshold: 0.39 f1: 0.6599292572006064\n",
            "[tester] precision=0.6821, recall=0.6376, f1=0.6591\n",
            "threshold: 0.40 f1: 0.659077393594427\n",
            "[tester] precision=0.6874, recall=0.6328, f1=0.6590\n",
            "threshold: 0.41 f1: 0.6589644843816859\n",
            "[tester] precision=0.6905, recall=0.6261, f1=0.6567\n",
            "threshold: 0.42 f1: 0.6567241379310345\n",
            "[tester] precision=0.6939, recall=0.6175, f1=0.6535\n",
            "threshold: 0.43 f1: 0.6535049573838928\n",
            "[tester] precision=0.6995, recall=0.6109, f1=0.6522\n",
            "threshold: 0.44 f1: 0.6522196876645026\n",
            "[tester] precision=0.7023, recall=0.6034, f1=0.6491\n",
            "threshold: 0.45 f1: 0.6491026434444347\n",
            "[tester] precision=0.7056, recall=0.5957, f1=0.6460\n",
            "threshold: 0.46 f1: 0.6459893048128341\n",
            "[tester] precision=0.7101, recall=0.5894, f1=0.6442\n",
            "threshold: 0.47 f1: 0.6441530447278607\n",
            "[tester] precision=0.7126, recall=0.5779, f1=0.6382\n",
            "threshold: 0.48 f1: 0.6382283536031947\n",
            "[tester] precision=0.7162, recall=0.5692, f1=0.6343\n",
            "threshold: 0.49 f1: 0.634307170986354\n",
            "[tester] precision=0.7219, recall=0.5610, f1=0.6313\n",
            "threshold: 0.50 f1: 0.6313355530891601\n",
            "best f1 on dev: 0.669272030651341 threshold: 0.28\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jZTAhJYXPCV",
        "colab_type": "text"
      },
      "source": [
        "# Testing Model on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6YCWmV3XL37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args[\"threshold\"] = 0.28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctmm0CjUZD4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(**args):\n",
        "    \"\"\"Inference using model.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Predicting...\")\n",
        "\n",
        "    # define model\n",
        "    model_args = {\n",
        "        \"vocab_size\": args[\"vocab_size\"],\n",
        "        \"padding_idx\": args[\"padding_idx\"],\n",
        "        \"pretrained_embed\": None,\n",
        "    }\n",
        "    model = Model(model_args)\n",
        "    load_model(model, model_path, use_cuda=True)\n",
        "\n",
        "    # define predictor\n",
        "    predictor = Predictor(batch_size=128, use_cuda=False)\n",
        "\n",
        "    # predict\n",
        "    data_test = args[\"data_test\"]\n",
        "    threshold = args[\"threshold\"]\n",
        "    y_pred = predictor.predict(model, data_test, threshold=threshold)\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjH6eB2BacpZ",
        "colab_type": "code",
        "outputId": "307030da-eaee-442d-92b8-40617d7fb27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "infer(**args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting...\n",
            "[tester] precision=0.6235, recall=0.7313, f1=0.6731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYPXqVVsb5lw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}